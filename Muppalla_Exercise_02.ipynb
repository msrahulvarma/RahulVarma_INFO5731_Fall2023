{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msrahulvarma/RahulVarma_INFO5731_Fall2023/blob/main/Muppalla_Exercise_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW5_oFVd9-pY"
      },
      "source": [
        "## The second In-class-exercise (09/13/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kindly use the provided .ipynb document to write your code or respond to the questions. Avoid generating a new file.\n",
        "Execute all the cells before your final submission."
      ],
      "metadata": {
        "id": "mAzh1U0sE5I5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This in-class exercise is due tomorrow September 14, 2023 at 11:59 PM. No late submissions will be considered."
      ],
      "metadata": {
        "id": "PpgvZQdRE-HV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QBZI-je9-pZ"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWoKpYQT9-pa"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting research question (or practical question or something innovative) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-LmNR3kw9-pa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "080e720f-33b7-4f65-8dbe-271c6cbbf1ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPlease write you answer here:\\nResearch Question:\\nHow do urban green spaces (like parks) affect the mental well-being of individuals living in metropolitan areas?\\n\\nData to be Collected:\\n\\nLocation Data - Geographical coordinates of all urban green spaces in selected metropolitan areas.\\nSurvey Data - Surveys from residents of these areas about their mental well-being, frequency of visits to these green spaces, duration of visits, activities during visits, etc.\\nEnvironmental Data - Air quality, noise levels, and other environmental metrics for these green spaces.\\nDemographic Data - Age, gender, occupation, and other demographic details of the survey participants.\\nAmount of Data Needed:\\n\\nAt least data from 500 green spaces.\\nSurveys from at least 10,000 residents.\\nSteps for Collecting and Saving Data:\\n\\nLocation Data:\\n\\nUse city planning websites or services like Google Maps API to gather geographical data of green spaces.\\nStore the data in a CSV file with columns: GreenSpace_Name, Latitude, Longitude.\\nSurvey Data:\\n\\nDesign an online survey using platforms like SurveyMonkey or Google Forms.\\nDistribute the survey through social media, local community websites, and email.\\nStore the responses in a database or CSV file with columns like Participant_ID, Visit_Frequency, Duration, WellBeing_Score, etc.\\nEnvironmental Data:\\n\\nCollaborate with local environmental agencies or use online resources like the World Air Quality Index.\\nStore the data in a CSV file with columns: GreenSpace_Name, Air_Quality, Noise_Level.\\nDemographic Data:\\n\\nThis data can be collected as part of the survey. Make sure to include questions about age, gender, occupation, etc. in the survey.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "Research Question:\n",
        "How do urban green spaces (like parks) affect the mental well-being of individuals living in metropolitan areas?\n",
        "\n",
        "Data to be Collected:\n",
        "\n",
        "Location Data - Geographical coordinates of all urban green spaces in selected metropolitan areas.\n",
        "Survey Data - Surveys from residents of these areas about their mental well-being, frequency of visits to these green spaces, duration of visits, activities during visits, etc.\n",
        "Environmental Data - Air quality, noise levels, and other environmental metrics for these green spaces.\n",
        "Demographic Data - Age, gender, occupation, and other demographic details of the survey participants.\n",
        "Amount of Data Needed:\n",
        "\n",
        "At least data from 500 green spaces.\n",
        "Surveys from at least 10,000 residents.\n",
        "Steps for Collecting and Saving Data:\n",
        "\n",
        "Location Data:\n",
        "\n",
        "Use city planning websites or services like Google Maps API to gather geographical data of green spaces.\n",
        "Store the data in a CSV file with columns: GreenSpace_Name, Latitude, Longitude.\n",
        "Survey Data:\n",
        "\n",
        "Design an online survey using platforms like SurveyMonkey or Google Forms.\n",
        "Distribute the survey through social media, local community websites, and email.\n",
        "Store the responses in a database or CSV file with columns like Participant_ID, Visit_Frequency, Duration, WellBeing_Score, etc.\n",
        "Environmental Data:\n",
        "\n",
        "Collaborate with local environmental agencies or use online resources like the World Air Quality Index.\n",
        "Store the data in a CSV file with columns: GreenSpace_Name, Air_Quality, Noise_Level.\n",
        "Demographic Data:\n",
        "\n",
        "This data can be collected as part of the survey. Make sure to include questions about age, gender, occupation, etc. in the survey.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlxTLRNm9-pa"
      },
      "source": [
        "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QpWOgjHi9-pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c19630-4d5d-43b3-9590-b69a706ce89a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(  GreenSpace_Name   Latitude   Longitude\n",
              " 0          Park_0  36.689423  -91.301910\n",
              " 1          Park_1  39.570898 -100.726211\n",
              " 2          Park_2  37.136489 -105.621752\n",
              " 3          Park_3  34.772593  -89.955794\n",
              " 4          Park_4  38.371716  -87.068177,\n",
              "   Participant_ID Visit_Frequency  WellBeing_Score\n",
              " 0  Participant_0          Weekly                2\n",
              " 1  Participant_1           Daily               10\n",
              " 2  Participant_2          Weekly                8\n",
              " 3  Participant_3         Monthly                1\n",
              " 4  Participant_4          Rarely                5,\n",
              "   GreenSpace_Name     Air_Quality Noise_Level\n",
              " 0          Park_0        Moderate         Low\n",
              " 1          Park_1  Very Unhealthy    Moderate\n",
              " 2          Park_2       Unhealthy    Moderate\n",
              " 3          Park_3        Moderate         Low\n",
              " 4          Park_4       Unhealthy    Moderate,\n",
              "   Participant_ID  Age Gender  Occupation\n",
              " 0  Participant_0   28   Male     Student\n",
              " 1  Participant_1   37  Other    Employed\n",
              " 2  Participant_2   29   Male  Unemployed\n",
              " 3  Participant_3   62   Male     Student\n",
              " 4  Participant_4   39  Other    Employed)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "# You code here (Please add comments in the code):\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Mock data generation\n",
        "\n",
        "# 1. Location Data\n",
        "green_spaces = [f\"Park_{i}\" for i in range(1000)]\n",
        "latitudes = [random.uniform(34.0, 42.0) for _ in range(1000)]  # Random latitudes for US metropolitan areas\n",
        "longitudes = [random.uniform(-118.0, -75.0) for _ in range(1000)]  # Random longitudes for US metropolitan areas\n",
        "location_data = pd.DataFrame({\n",
        "    \"GreenSpace_Name\": green_spaces,\n",
        "    \"Latitude\": latitudes,\n",
        "    \"Longitude\": longitudes\n",
        "})\n",
        "\n",
        "# 2. Survey Data\n",
        "participants = [f\"Participant_{i}\" for i in range(1000)]\n",
        "visit_frequencies = [\"Daily\", \"Weekly\", \"Monthly\", \"Rarely\"]\n",
        "wellbeing_scores = [random.randint(1, 10) for _ in range(1000)]  # 1-10 wellbeing score\n",
        "visit_frequency_data = [random.choice(visit_frequencies) for _ in range(1000)]\n",
        "survey_data = pd.DataFrame({\n",
        "    \"Participant_ID\": participants,\n",
        "    \"Visit_Frequency\": visit_frequency_data,\n",
        "    \"WellBeing_Score\": wellbeing_scores\n",
        "})\n",
        "\n",
        "# 3. Environmental Data\n",
        "air_qualities = [\"Good\", \"Moderate\", \"Unhealthy\", \"Very Unhealthy\"]\n",
        "noise_levels = [\"Low\", \"Moderate\", \"High\"]\n",
        "environmental_data = pd.DataFrame({\n",
        "    \"GreenSpace_Name\": green_spaces,\n",
        "    \"Air_Quality\": [random.choice(air_qualities) for _ in range(1000)],\n",
        "    \"Noise_Level\": [random.choice(noise_levels) for _ in range(1000)]\n",
        "})\n",
        "\n",
        "# 4. Demographic Data\n",
        "ages = [random.randint(18, 70) for _ in range(1000)]\n",
        "genders = [\"Male\", \"Female\", \"Other\", \"Prefer not to say\"]\n",
        "occupations = [\"Student\", \"Employed\", \"Unemployed\", \"Retired\"]\n",
        "demographic_data = pd.DataFrame({\n",
        "    \"Participant_ID\": participants,\n",
        "    \"Age\": ages,\n",
        "    \"Gender\": [random.choice(genders) for _ in range(1000)],\n",
        "    \"Occupation\": [random.choice(occupations) for _ in range(1000)]\n",
        "})\n",
        "\n",
        "location_data.head(), survey_data.head(), environmental_data.head(), demographic_data.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px6wgvog9-pa"
      },
      "source": [
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2013-2023).\n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P5rjlclf9-pb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05b64a38-e493-43f4-acca-c01c3340763d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collected 500 articles and saved to 'articles.json'.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "\n",
        "def fetch_google_scholar_articles(query, start_year, end_year, num_articles):\n",
        "    base_url = \"https://scholar.google.com/scholar\"\n",
        "    articles = []\n",
        "    articles_per_page = 20\n",
        "\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.1234.0 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    for start in range(0, num_articles, articles_per_page):\n",
        "        params = {\n",
        "            \"q\": query,\n",
        "            \"as_ylo\": start_year,\n",
        "            \"as_yhi\": end_year,\n",
        "            \"start\": start\n",
        "        }\n",
        "\n",
        "        response = requests.get(base_url, params=params, headers=headers)\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            print(\"Failed to retrieve some articles.\")\n",
        "            continue\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        results = soup.find_all('div', {'class': 'gs_ri'})\n",
        "\n",
        "        for result in results:\n",
        "            title = result.find('h3', {'class': 'gs_rt'}).text if result.find('h3', {'class': 'gs_rt'}) else None\n",
        "            venue_info = result.find('div', {'class': 'gs_a'}).text.split('-') if result.find('div', {'class': 'gs_a'}) else [None, None]\n",
        "            authors, year = venue_info[0].strip(), venue_info[-1].strip()\n",
        "            abstract = result.find('div', {'class': 'gs_rs'}).text if result.find('div', {'class': 'gs_rs'}) else None\n",
        "\n",
        "            articles.append({\n",
        "                \"title\": title,\n",
        "                \"venue\": year,\n",
        "                \"year\": year,\n",
        "                \"authors\": authors,\n",
        "                \"abstract\": abstract\n",
        "            })\n",
        "\n",
        "            if len(articles) >= num_articles:\n",
        "                return articles\n",
        "\n",
        "    return articles\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    articles = fetch_google_scholar_articles(\"information retrieval\", 2000, 2023, 1000)\n",
        "\n",
        "    with open(\"articles.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
        "        json.dump(articles, json_file, indent=4, ensure_ascii=False)\n",
        "\n",
        "    print(f\"Collected {len(articles)} articles and saved to 'articles.json'.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do either of the question-4 tasks given below."
      ],
      "metadata": {
        "id": "yCQpbJnwTxAB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT3CNj_V9-pb"
      },
      "source": [
        "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data.\n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FymVNKVi9-pb"
      },
      "outputs": [],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4 (10 points):\n",
        "\n",
        "In this task, you are required to identify and utilize online tools for web scraping data from websites without the need for coding, with a specific focus on Parsehub. The objective is to gather data and save it in formats like CSV, Excel, or any other suitable file format.\n",
        "\n",
        "You have to mention an introduction to the tool which ever you prefer to use, steps to follow for web scrapping and the final output of the data collected.\n",
        "\n",
        "Upload a document (Word or PDF File) in the same repository and you can add the link in the ipynb file."
      ],
      "metadata": {
        "id": "wOeAr9TJTBgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the link to the document here\n",
        "A=(\"https://github.com/msrahulvarma/RahulVarma_INFO5731_Fall2023/blob/main/Rahul%20varma_amezon%20scraping.pdf\")\n",
        "print(A)"
      ],
      "metadata": {
        "id": "N20TjXLmTG1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c3f5659-28a2-4123-d82e-173a8580865f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://github.com/msrahulvarma/RahulVarma_INFO5731_Fall2023/blob/main/Rahul%20varma_amezon%20scraping.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Ts-t3cu-Hip"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}